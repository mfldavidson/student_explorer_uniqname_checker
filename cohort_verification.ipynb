{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniqname Error Finder for Student Explorer application\n",
    "In [Student Explorer](https://github.com/tl-its-umich-edu/student_explorer/), if a cohort is created with a student uniqname that doesn't match to a student in edwprod.world CNLYR002 DM_STDNT table, the way this manifests in the application is that the advisor sees a student in their \"My Students\" view named \"Not Happened Yet\".\n",
    "\n",
    "DM_STDNT contains any student who has taken a course at the University of Michigan-Ann Arbor that uses Canvas. This generally includes all undergraduate and graduate students enrolled in residential programs and some students enrolled in online programs (if the program uses Canvas; some don't).\n",
    "\n",
    "This program was created in order to figure out which cohorts have \"bad\" student uniqname values and which values are causing the error.\n",
    "\n",
    "The intention is that you will go to the advisor to let them know about the error so that they can decide whether or not to fix it. Detailed below are some common reasons that the uniqname causes an error and the fix.\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Reason</th>\n",
    "        <th>Fix</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            The uniqname contains a typo\n",
    "        </td>\n",
    "        <td>\n",
    "            Get the correct uniqname from the advisor\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            The student ended up not enrolling at U-M\n",
    "        </td>\n",
    "        <td>\n",
    "            Remove, if the student will never enroll\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            The student delayed their start term\n",
    "        </td>\n",
    "        <td>\n",
    "            Keep, if student will eventually enroll\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            The student is a PhD candidate no longer taking classes\n",
    "        </td>\n",
    "        <td>\n",
    "            Remove, if the student will not take any more classes\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this program\n",
    "\n",
    "### .py vs .ipynb\n",
    "\n",
    "Files are provided in both .py (Python program) and .ipynb (Jupyter Notebook) format. You can choose which to use. The program was written in a Jupyter Notebook and then exported to Python, so the comments in the Python program are more difficult to read. I recommend running the program in the Jupyter Notebook the first time and running it step by step so that you can become familiar with what the program is doing, but after the first time it may be more convenient to use the Python program.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. You must have the read-only credentials (username and password) to the Student Explorer production MySQL database.\n",
    "\n",
    "1. You must have your own read-only credentials (username and password) for the U-M Enterprise Data Warehouse edwprod.world that provide you access to (at minimum) CNLYR002 tables BG_STDNT_CHRT_MNTR, DM_CHRT, and DM_STDNT.\n",
    "\n",
    "1. You must have the connection string from the tnsnames.ora file for connecting to edwprod.world (usually just a section in a larger tnsnames.ora file for all U-M enterprise data warehouses)\n",
    "\n",
    "### Initial setup (first time only)\n",
    "\n",
    "1. Clone this repo to your computer by navigating to the directory/folder where you want it and entering `git clone https://github.com/mfldavidson/student_explorer_uniqname_error_finder.git` in your command line.\n",
    "\n",
    "1. Create a virtual environment (`python3 -m venv whateveryouwanttonameit`) wherever you keep your virtual environments.\n",
    "\n",
    "1. Activate the virtual environment (`source whateveryounamedthevirtualenv/bin/activate` if you are on a Mac, or `source whateveryounamedthevirtualenv/Scripts/activate` if you are on a PC).\n",
    "\n",
    "1. Install all necessary libraries by navigating to the repo and then running the command `pip install -r requirements.txt`\n",
    "\n",
    "1. Create a file named `db_creds.py` and enter the following code in it, replacing the word 'REPLACE' with the appropriate credentials and string.\n",
    "\n",
    "```\n",
    "# Your own Oracle edwprod.world read-only credentials\n",
    "oracreds = {\n",
    "    'user' : 'REPLACE',\n",
    "    'password' : 'REPLACE'\n",
    "}\n",
    "\n",
    "# Student Explorer production MySQL read-only credentials\n",
    "mysqlcreds = {\n",
    "    'user': 'REPLACE',\n",
    "    'password': 'REPLACE'\n",
    "}\n",
    "\n",
    "# The exact string after 'edwprod.world=' from the tnsnames.ora file--should start with (DESCRIPTION=\n",
    "dsn_tns = '''REPLACE'''\n",
    "\n",
    "```\n",
    "\n",
    "### Directions for running the program after setup\n",
    "\n",
    "1. Activate the virtual environment (`source whateveryounamedthevirtualenv/bin/activate` if you are on a Mac, or `source whateveryounamedthevirtualenv/Scripts/activate` if you are on a PC).\n",
    "\n",
    "1. Connect to the [U-M VPN](https://its.umich.edu/enterprise/wifi-networks/vpn).\n",
    "\n",
    "1. Navigate in the command line to the directory where these files are located on your computer.\n",
    "\n",
    "1. There are different instructions for using the .ipynb method vs .py:\n",
    "\n",
    "\n",
    "- If you are choosing to run the Jupyter Notebook: run the command `jupyter notebook` in your command line, then open the Jupyter Notebook in the browser window that opens. You may opt to run the Notebook line by line or all at once; it's up to you.\n",
    "- If you are choosing to run the Python program: run the command `python cohort_verification.py` in your command line.\n",
    "\n",
    "The program should create a CSV named `uniqname_errors.csv` that outputs, for every cohort in Student Explorer that has a bad student uniqname value, the value that caused the error, the affected cohort, and the advisor to whom the student was mapped. This way, you can go to that advisor to address the issue. Note that the same student may appear multiple times if they are in multiple cohorts or have multiple advisors assigned to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql # For connecting to the Student Explorer MySQL database\n",
    "import cx_Oracle # For connecting to the edwprod.world Oracle database\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run db_creds # Get the database credentials stored in db_creds.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the cohorts with bad data\n",
    "We can find out which cohorts have \"bad\" data in them (i.e. a uniqname for a student who didn't match a student in edwprod.world CNLYR002.DM_STDNT) by querying edwprod.world. We will then use this list of cohorts to find the \"bad\" data in each cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the connection to edwprod.world using credentials stored in db_creds.py\n",
    "# Make sure to not put your username, password, or tns data in this file!\n",
    "conora = cx_Oracle.connect(user=oracreds['user'], password=oracreds['password'], dsn=dsn_tns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQL string to get our cohorts with bad data\n",
    "query_cohorts = ('SELECT DISTINCT '\n",
    "                    'COHORT.CHRT_KEY \"Cohort Key\", '\n",
    "                    'COHORT.CHRT_CD \"Cohort Code\", '\n",
    "                    'COHORT.CHRT_DES \"Cohort Name\" '\n",
    "                'FROM CNLYR002.BG_STDNT_CHRT_MNTR BRIDGE '\n",
    "                'LEFT JOIN CNLYR002.DM_CHRT COHORT ON COHORT.CHRT_KEY = BRIDGE.CHRT_KEY '\n",
    "                'WHERE BRIDGE.STDNT_KEY < 0 '\n",
    "                'ORDER BY COHORT.CHRT_CD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the SQL query and load the data into a data frame\n",
    "bad_cohorts = pd.read_sql(query_cohorts, conora)\n",
    "bad_cohorts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the processed cohort data\n",
    "We can access the list of student-advisors mappings that were successfully processed using the edwprod.world database. We will then load that data into a dataframe named valid_cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string of all cohorts to query for\n",
    "cohort_str_key = bad_cohorts.astype({'Cohort Key':'str'})['Cohort Key'].str.cat(sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the query with our cohort_str\n",
    "query_valid = ('SELECT DISTINCT STU.STDNT_UM_UNQNM \"Student\", '\n",
    "                'BRIDGE.CHRT_KEY \"Cohort Key\" '\n",
    "                'FROM CNLYR002.BG_STDNT_CHRT_MNTR BRIDGE '\n",
    "                'LEFT JOIN CNLYR002.DM_STDNT STU ON STU.STDNT_KEY = BRIDGE.STDNT_KEY '\n",
    "                f'WHERE BRIDGE.CHRT_KEY IN ({cohort_str_key}) '\n",
    "                'AND BRIDGE.STDNT_KEY > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the query and load it into a data frame\n",
    "valid_stus = pd.read_sql(query_valid, conora)\n",
    "valid_stus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our uniqnames to lowercase to match the raw data\n",
    "valid_stus.Student = valid_stus.Student.str.lower()\n",
    "valid_stus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conora.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the raw cohort data\n",
    "We can access the list of student-advisor mappings that were provided to us by the advisor and uploaded in Student Explorer management using the MySQL database. We will then load that data into a dataframe named raw_cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the connection\n",
    "conmysql = pymysql.connect(host='tl-prod-mysql.aws.vdc.it.umich.edu',\n",
    "                      port=3306,\n",
    "                      user=mysqlcreds['user'],\n",
    "                      password=mysqlcreds['password'],\n",
    "                      database='student_explorer',\n",
    "                      cursorclass=pymysql.cursors.Cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string of the cohort codes to use in the query like we did with key\n",
    "cohort_str_code = bad_cohorts['Cohort Code'].str.cat(sep=\"', '\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQL string to get raw data for the bad cohorts\n",
    "query_raw = ('SELECT student_id \"Student\", '\n",
    "             'mentor_id \"Advisor\", '\n",
    "             'cohort_id \"Cohort Code\"'\n",
    "             'FROM management_studentcohortmentor '\n",
    "             f'''WHERE cohort_id IN ('{cohort_str_code}');''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cohort = pd.read_sql(query_raw, conmysql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cohort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conmysql.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the data frames\n",
    "We now have a data frame of students who we know are valid, and the raw input of students. We want to join them so we can see which students are in the raw input but not in the list of valid students. Those are our \"bad\" students. We need to also join the bad cohort data frame because it contains the \"bridge\" between the cohort information in the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge valid_stus and bad_cohorts so we have the cohort code to go with valid_stus\n",
    "valid_cohorts = valid_stus.merge(bad_cohorts, on='Cohort Key', how='outer')\n",
    "valid_cohorts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge valid_cohorts with raw_cohorts now that we can use the Cohort Code in both\n",
    "merged = valid_cohorts.merge(raw_cohort, how='outer', on=['Student','Cohort Code'])\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a data frame filtered from merged where Cohort Name is null\n",
    "# If Cohort Name is null then we know they weren't in valid_stus\n",
    "bad_stus = merged[ merged['Cohort Name'].isnull()].copy()\n",
    "bad_stus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns since we know they contain null data\n",
    "bad_stus.drop(['Cohort Key', 'Cohort Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the cohort dataframe in so we have the name of the cohort\n",
    "# This allows us to use the name when communicating with the advisor\n",
    "final = bad_stus.merge(bad_cohorts, on='Cohort Code', how='left')\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CSV File\n",
    "Create a CSV file with the \"bad students,\" the cohort, and advisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for the advisor's email for your convenience in emailing them\n",
    "final['Advisor Email'] = final.Advisor.apply(lambda x: x+'@umich.edu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "final.to_csv('uniqname_errors.csv', index=False, columns=['Student', 'Advisor', 'Advisor Email', 'Cohort Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
